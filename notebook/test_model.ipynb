{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch sounddevice numpy soundfile streamlit\n",
    "!pip install librosa\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "!pip install datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import soundfile as sf\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "import librosa\n",
    "import time\n",
    "from jiwer import wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the ASR pipeline with caching and GPU support\n",
    "@st.cache_resource\n",
    "def load_pipeline():\n",
    "    model_name = \"/home/adhippc/miniconda3/envs/Fuse_ASR/codes/model\"  # Update the path to your local model\n",
    "    whisper_pipeline = pipeline(\"automatic-speech-recognition\", model=model_name, device=0)  # Use GPU (device=0)\n",
    "    return whisper_pipeline\n",
    "\n",
    "# Initialize the pipeline\n",
    "whisper_pipeline = load_pipeline()\n",
    "st.title(\"Voice-to-Text Converter (Nepali)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_folder = 'paragraphs'\n",
    "audio_folder = 'audios'\n",
    "\n",
    "total_wer = 0\n",
    "total_latency = 0\n",
    "num_files = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "total_wer = 0\n",
    "total_latency = 0\n",
    "chunk_duration = 30\n",
    "\n",
    "# Loop through audio and text files from 100 to 200\n",
    "for i in range(100, 201):\n",
    "    audio_file = os.path.join(audio_folder, f'audio_{i}.mp3')\n",
    "    text_file = os.path.join(text_folder, f'paragraph_{i}.txt')\n",
    "\n",
    "    # Load audio and text\n",
    "    with open(text_file, 'r') as f:\n",
    "        reference_text = f.read().strip()\n",
    "\n",
    "    # Load audio file\n",
    "    audio_data, sr = librosa.load(audio_file, sr=16000)\n",
    "\n",
    "    # Split audio into chunks\n",
    "    num_chunks = int(len(audio_data) / (sr * chunk_duration)) + 1\n",
    "\n",
    "    chunk_predictions = []\n",
    "    for j in range(num_chunks):\n",
    "        start_sample = j * sr * chunk_duration\n",
    "        end_sample = min((j + 1) * sr * chunk_duration, len(audio_data))\n",
    "        audio_chunk = audio_data[start_sample:end_sample]\n",
    "\n",
    "        # Measure latency and transcribe audio chunk\n",
    "        start_time = time.time()\n",
    "        prediction = whisper_pipeline(audio_chunk)[\"text\"]\n",
    "        latency = time.time() - start_time\n",
    "        chunk_predictions.append(prediction)\n",
    "\n",
    "    # Combine predictions from all chunks\n",
    "    full_prediction = \" \".join(chunk_predictions)\n",
    "\n",
    "    # Calculate WER\n",
    "    wer_value = wer(reference_text, full_prediction)\n",
    "\n",
    "    # Accumulate WER and latency\n",
    "    total_wer += wer_value\n",
    "    total_latency += latency\n",
    "\n",
    "    print(f'Audio {i}: WER = {wer_value:.4f}, Latency = {latency:.4f} seconds')\n",
    "\n",
    "# Optionally, you can print the total WER and latency after the loop\n",
    "average_wer = total_wer / (101)  # 101 because it goes from 100 to 200\n",
    "average_latency = total_latency / (101)\n",
    "\n",
    "print(f'Total WER: {total_wer:.4f}, Average WER: {average_wer:.4f}')\n",
    "print(f'Total Latency: {total_latency:.4f} seconds, Average Latency: {average_latency:.4f} seconds')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fuse_ASR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
