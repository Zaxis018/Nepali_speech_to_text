{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7cedebad581d4da8a0550a00d12e22ab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ed083a6195374b6eb9984d9ba272a2e5","IPY_MODEL_a22973f4928b455e8ad60f4e85acc230","IPY_MODEL_b5dea084071945f79596edfff743ec45"],"layout":"IPY_MODEL_a82086c910a749f69e377b763c3b7424"}},"ed083a6195374b6eb9984d9ba272a2e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04a05bdb65584670bd74af3b8fce17d6","placeholder":"​","style":"IPY_MODEL_0de621b1197141dd9daa30fabb88c021","value":"Map: 100%"}},"a22973f4928b455e8ad60f4e85acc230":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fd7cbacc6d24a90bff154b6c758ef19","max":381,"min":0,"orientation":"horizontal","style":"IPY_MODEL_04d19e1d14a24e3a8da979d63003da2a","value":381}},"b5dea084071945f79596edfff743ec45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d4744c0907db4296b0824c2502abe93a","placeholder":"​","style":"IPY_MODEL_44bd8cc50bc44220ab8dc94c6efe25ff","value":" 381/381 [00:53&lt;00:00,  2.99s/ examples]"}},"a82086c910a749f69e377b763c3b7424":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04a05bdb65584670bd74af3b8fce17d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0de621b1197141dd9daa30fabb88c021":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7fd7cbacc6d24a90bff154b6c758ef19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04d19e1d14a24e3a8da979d63003da2a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d4744c0907db4296b0824c2502abe93a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44bd8cc50bc44220ab8dc94c6efe25ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d830b8d81ca468bb99309f6027a5892":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_20cfa50be60f4c8eb0fcdd89e0b9fb5a","IPY_MODEL_cb21a176645d46a8a38418df16eebea5","IPY_MODEL_e921cdaf19654e43ac0c0cffe6e52dda"],"layout":"IPY_MODEL_ce3e4996a7174920bd3df8a8bd4a1a27"}},"20cfa50be60f4c8eb0fcdd89e0b9fb5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_906472cc5684426ca4cdb3acc9002d5d","placeholder":"​","style":"IPY_MODEL_a1fdbdb3fc0348bd9a2c73437c467c5d","value":"Map: 100%"}},"cb21a176645d46a8a38418df16eebea5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_346e4f1452e64905a3d980a94db1f4f0","max":205,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf08fabde6fb4f07819040e417f6a3ed","value":205}},"e921cdaf19654e43ac0c0cffe6e52dda":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f710ff78faef40d7970e6c36376bf86a","placeholder":"​","style":"IPY_MODEL_b52f94ca818e496ca12fd91139dc067a","value":" 205/205 [00:29&lt;00:00,  1.65s/ examples]"}},"ce3e4996a7174920bd3df8a8bd4a1a27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"906472cc5684426ca4cdb3acc9002d5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1fdbdb3fc0348bd9a2c73437c467c5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"346e4f1452e64905a3d980a94db1f4f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf08fabde6fb4f07819040e417f6a3ed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f710ff78faef40d7970e6c36376bf86a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b52f94ca818e496ca12fd91139dc067a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Necessary Libraries\n","metadata":{"id":"iKJiVWB-oJxa"}},{"cell_type":"code","source":"\n!pip install --upgrade datasets[audio] transformers accelerate evaluate jiwer tensorboard gradio\n!pip install jinja2","metadata":{"id":"YlUM7nrqnPga","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dcde84a7-21f6-4ff6-8147-c46d17d47dfc","execution":{"iopub.status.busy":"2024-09-26T08:35:13.682371Z","iopub.execute_input":"2024-09-26T08:35:13.682847Z","iopub.status.idle":"2024-09-26T08:36:00.471076Z","shell.execute_reply.started":"2024-09-26T08:35:13.682813Z","shell.execute_reply":"2024-09-26T08:36:00.470148Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.2)\nCollecting transformers\n  Downloading transformers-4.45.0-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting jiwer\n  Downloading jiwer-3.0.4-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (2.16.2)\nCollecting tensorboard\n  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\nCollecting gradio\n  Downloading gradio-4.44.0-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: datasets[audio] in /opt/conda/lib/python3.10/site-packages (3.0.0)\nCollecting datasets[audio]\n  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets[audio]) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.25.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (6.0.2)\nRequirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.12.1)\nRequirement already satisfied: librosa in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.10.2.post1)\nRequirement already satisfied: soxr>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.5.0.post1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nCollecting tokenizers<0.21,>=0.20 (from transformers)\n  Downloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\nRequirement already satisfied: click<9.0.0,>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from jiwer) (8.1.7)\nCollecting rapidfuzz<4,>=3 (from jiwer)\n  Downloading rapidfuzz-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.62.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.6)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.20.3)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (70.0.0)\nRequirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.16.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.0.4)\nRequirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (22.1.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.4.0)\nRequirement already satisfied: fastapi<1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.111.0)\nCollecting ffmpy (from gradio)\n  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\nCollecting gradio-client==1.3.0 (from gradio)\n  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\nRequirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.27.0)\nRequirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.4.0)\nRequirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.4)\nRequirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.5)\nRequirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.7.5)\nRequirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.10.4)\nRequirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (10.3.0)\nRequirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.9.2)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\nRequirement already satisfied: python-multipart>=0.0.9 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.0.9)\nCollecting ruff>=0.2.2 (from gradio)\n  Downloading ruff-0.6.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\nCollecting semantic-version~=2.0 (from gradio)\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\nCollecting tomlkit==0.12.0 (from gradio)\n  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: typer<1.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.12.3)\nRequirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.12.2)\nCollecting urllib3~=2.0 (from gradio)\n  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.30.1)\nRequirement already satisfied: websockets<13.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.3.0->gradio) (12.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.0)\nRequirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/conda/lib/python3.10/site-packages (from fastapi<1.0->gradio) (0.37.2)\nRequirement already satisfied: fastapi-cli>=0.0.2 in /opt/conda/lib/python3.10/site-packages (from fastapi<1.0->gradio) (0.0.4)\nRequirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from fastapi<1.0->gradio) (5.10.0)\nRequirement already satisfied: email_validator>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from fastapi<1.0->gradio) (2.1.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (4.0.3)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets[audio]) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets[audio]) (2024.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.23.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets[audio]) (3.3.2)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->datasets[audio]) (1.16.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\nRequirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (3.0.1)\nRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.14.1)\nRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.4.2)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (5.1.1)\nRequirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (0.60.0)\nRequirement already satisfied: pooch>=1.1 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.8.2)\nRequirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.0.8)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->datasets[audio]) (2.22)\nRequirement already satisfied: dnspython>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi<1.0->gradio) (2.6.1)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa->datasets[audio]) (0.43.0)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.1->librosa->datasets[audio]) (3.11.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa->datasets[audio]) (3.5.0)\nRequirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0->gradio) (0.6.1)\nRequirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0->gradio) (1.0.1)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0->gradio) (0.19.0)\nRequirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi<1.0->gradio) (0.22.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\nDownloading transformers-4.45.0-py3-none-any.whl (9.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jiwer-3.0.4-py3-none-any.whl (21 kB)\nDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading gradio-4.44.0-py3-none-any.whl (18.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\nDownloading datasets-3.0.1-py3-none-any.whl (471 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rapidfuzz-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading ruff-0.6.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nDownloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\nInstalling collected packages: urllib3, tomlkit, semantic-version, ruff, rapidfuzz, ffmpy, tensorboard, jiwer, tokenizers, gradio-client, datasets, transformers, evaluate, gradio\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.18\n    Uninstalling urllib3-1.26.18:\n      Successfully uninstalled urllib3-1.26.18\n  Attempting uninstall: tomlkit\n    Found existing installation: tomlkit 0.13.2\n    Uninstalling tomlkit-0.13.2:\n      Successfully uninstalled tomlkit-0.13.2\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.16.2\n    Uninstalling tensorboard-2.16.2:\n      Successfully uninstalled tensorboard-2.16.2\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: datasets\n    Found existing installation: datasets 3.0.0\n    Uninstalling datasets-3.0.0:\n      Successfully uninstalled datasets-3.0.0\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.44.2\n    Uninstalling transformers-4.44.2:\n      Successfully uninstalled transformers-4.44.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndistributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.9.0 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.3 which is incompatible.\nrapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.0 which is incompatible.\ntensorflow 2.16.1 requires tensorboard<2.17,>=2.16, but you have tensorboard 2.18.0 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-3.0.1 evaluate-0.4.3 ffmpy-0.4.0 gradio-4.44.0 gradio-client-1.3.0 jiwer-3.0.4 rapidfuzz-3.10.0 ruff-0.6.7 semantic-version-2.10.0 tensorboard-2.18.0 tokenizers-0.20.0 tomlkit-0.12.0 transformers-4.45.0 urllib3-2.2.1\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (3.1.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2) (2.1.5)\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset, DatasetDict\nfrom transformers import (\n    WhisperTokenizer,\n    WhisperProcessor,\n    WhisperFeatureExtractor,\n    WhisperForConditionalGeneration,\n    Seq2SeqTrainingArguments,\n    Seq2SeqTrainer,\n)","metadata":{"id":"hTogPtadoMaC","execution":{"iopub.status.busy":"2024-09-26T08:36:00.473070Z","iopub.execute_input":"2024-09-26T08:36:00.473416Z","iopub.status.idle":"2024-09-26T08:36:20.423106Z","shell.execute_reply.started":"2024-09-26T08:36:00.473381Z","shell.execute_reply":"2024-09-26T08:36:20.421534Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from datasets import Audio\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Union\n\nimport torch\nimport evaluate\n","metadata":{"id":"hIluEJIhpEbz","execution":{"iopub.status.busy":"2024-09-26T08:36:20.424828Z","iopub.execute_input":"2024-09-26T08:36:20.425557Z","iopub.status.idle":"2024-09-26T08:36:20.504549Z","shell.execute_reply.started":"2024-09-26T08:36:20.425517Z","shell.execute_reply":"2024-09-26T08:36:20.503435Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Defining Parameters","metadata":{"id":"qQSXhKq9q4Tu"}},{"cell_type":"code","source":"model_id = 'openai/whisper-small'\nout_dir = 'whisper_tiny_np'\nepochs = 50\nbatch_size = 4","metadata":{"id":"mqCI0E6apSPI","execution":{"iopub.status.busy":"2024-09-26T08:36:20.507123Z","iopub.execute_input":"2024-09-26T08:36:20.507485Z","iopub.status.idle":"2024-09-26T08:36:20.556845Z","shell.execute_reply.started":"2024-09-26T08:36:20.507451Z","shell.execute_reply":"2024-09-26T08:36:20.555829Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing the Dataset","metadata":{"id":"MAiHfW9bsLp9"}},{"cell_type":"code","source":"feature_extractor = WhisperFeatureExtractor.from_pretrained(model_id)\ntokenizer = WhisperTokenizer.from_pretrained(model_id, language='Nepali', task='transcribe')\nprocessor = WhisperProcessor.from_pretrained(model_id, language='Nepali', task='transcribe')\n","metadata":{"id":"QdW9exVpr2Kv","execution":{"iopub.status.busy":"2024-09-26T08:36:20.558425Z","iopub.execute_input":"2024-09-26T08:36:20.558854Z","iopub.status.idle":"2024-09-26T08:36:29.221669Z","shell.execute_reply.started":"2024-09-26T08:36:20.558810Z","shell.execute_reply":"2024-09-26T08:36:29.220684Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"854cc846e0fa4114a374c9cc57dd227f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a29808638a6d48fd823a9703af25f844"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95c591551b0c4d2489fff6ce1ebf00a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05a01621276b48269685de439590ad56"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12e9bcf2d73a481d9b89f44cbfbb16d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c6bd0757815448ea6a1f0f35b2e6999"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52bbee8d64f24df08f3d18804906085e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d1bf09ea4cb40c794a89c0bdd93dc59"}},"metadata":{}}]},{"cell_type":"code","source":"# atc_dataset_train = atc_dataset_train.cast_column('audio', Audio(sampling_rate=16000))\n# atc_dataset_valid = atc_dataset_valid.cast_column('audio', Audio(sampling_rate=16000))\ntrain_np = load_dataset(\"fsicoli/common_voice_19_0\", \"ne-NP\", split=\"train\", trust_remote_code=True)\nval_np = load_dataset(\"fsicoli/common_voice_19_0\", \"ne-NP\", split=\"test\", trust_remote_code=True)","metadata":{"id":"08nb_bNpsP_d","execution":{"iopub.status.busy":"2024-09-26T08:36:29.222951Z","iopub.execute_input":"2024-09-26T08:36:29.223296Z","iopub.status.idle":"2024-09-26T08:36:46.405918Z","shell.execute_reply.started":"2024-09-26T08:36:29.223247Z","shell.execute_reply":"2024-09-26T08:36:46.404943Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"common_voice_19_0.py:   0%|          | 0.00/8.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9db1296efd90449b833e947b9210dc26"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/4.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2b71aa2982248658954641a584a87d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"languages.py:   0%|          | 0.00/4.00k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a26853197b74a01b82a1cea141ae8ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"release_stats.py:   0%|          | 0.00/138k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25041e238f8446ca83b9fe305a73ee7d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"n_shards.json:   0%|          | 0.00/16.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08e103037b7a4f62b6401b42ab801668"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ne-NP_train_0.tar:   0%|          | 0.00/8.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45a46698b0d143699e73ad44dd087e78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ne-NP_dev_0.tar:   0%|          | 0.00/3.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d50295cd5903434cb6d7a73f40637677"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ne-NP_test_0.tar:   0%|          | 0.00/5.44M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a46c3c7dd9249ea9e73e23ef6697770"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ne-NP_other_0.tar:   0%|          | 0.00/16.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f014eb6e89f14b2dad9e02735709a213"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"ne-NP_invalidated_0.tar:   0%|          | 0.00/1.83M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbdfb31665f241c48641e89ef65689d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"transcript/ne-NP/train.tsv:   0%|          | 0.00/134k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ec137215ef24809a4e37b6275147388"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"transcript/ne-NP/dev.tsv:   0%|          | 0.00/50.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e587e3ad33a41769de5a53cf9484c86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"transcript/ne-NP/test.tsv:   0%|          | 0.00/71.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b86a2e5e947438d83f51a83f983ad8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"transcript/ne-NP/other.tsv:   0%|          | 0.00/223k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ccf0636491e4057b46181ae449675ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"transcript/ne-NP/invalidated.tsv:   0%|          | 0.00/23.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e61cb91a1d54fa4a62bb7d7c288e7ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31a1a9ba4cfa49eda5dd277d054a92fe"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 381it [00:00, 76523.00it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f862820ec29497f89242d128df40242"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 147it [00:00, 88118.15it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a68a229ce65b4492bb57c689f97e7756"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 205it [00:00, 59673.28it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating other split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abb59773c9bd4cfe8cd93a23eb3ed781"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 638it [00:00, 79772.42it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating invalidated split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f70a9c11a0544c08da57eca84f6b9aa"}},"metadata":{}},{"name":"stderr","text":"\nReading metadata...: 67it [00:00, 40662.48it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_np[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XOsgFw4as8pH","outputId":"60907d08-cbf9-4d40-e441-0b6ac1722ab3","execution":{"iopub.status.busy":"2024-09-26T08:36:46.407284Z","iopub.execute_input":"2024-09-26T08:36:46.407673Z","iopub.status.idle":"2024-09-26T08:37:01.108542Z","shell.execute_reply.started":"2024-09-26T08:36:46.407624Z","shell.execute_reply":"2024-09-26T08:37:01.107602Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'client_id': '9f8a47cee5574b287a8f93f5498d81115cf1dfbd718ead4f2265e4400f7de0f017a58a2c8c1245e0d3ceeccffa5b110322c4f784aa8a9785e3219557cb44395e',\n 'path': '/root/.cache/huggingface/datasets/downloads/extracted/2078d4f647abb87146c4e6361776aff17e038b4472a795fd02ab22d7c2574c59/ne-NP_train_0/common_voice_ne-NP_35314089.mp3',\n 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/2078d4f647abb87146c4e6361776aff17e038b4472a795fd02ab22d7c2574c59/ne-NP_train_0/common_voice_ne-NP_35314089.mp3',\n  'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n          7.00167766e-06, -4.02070254e-05, -3.65305859e-05]),\n  'sampling_rate': 48000},\n 'sentence': 'म पनि जान्छु है त अहिले लाई ।',\n 'up_votes': 4,\n 'down_votes': 0,\n 'age': 'thirties',\n 'gender': 'male_masculine',\n 'accent': 'nepali',\n 'locale': 'ne-NP',\n 'segment': '',\n 'variant': ''}"},"metadata":{}}]},{"cell_type":"markdown","source":"Resmapling at 16khz","metadata":{"id":"xi84opEa09hg"}},{"cell_type":"code","source":"train_np = train_np.cast_column('audio', Audio(sampling_rate=16000))\nval_np = val_np.cast_column('audio', Audio(sampling_rate=16000))","metadata":{"id":"LC58fpS702OG","execution":{"iopub.status.busy":"2024-09-26T08:37:01.109847Z","iopub.execute_input":"2024-09-26T08:37:01.110567Z","iopub.status.idle":"2024-09-26T08:37:01.125248Z","shell.execute_reply.started":"2024-09-26T08:37:01.110533Z","shell.execute_reply":"2024-09-26T08:37:01.124216Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_np = train_np.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])\nval_np = val_np.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])","metadata":{"id":"cjUSX-qo-GtX","execution":{"iopub.status.busy":"2024-09-26T08:37:01.126688Z","iopub.execute_input":"2024-09-26T08:37:01.127590Z","iopub.status.idle":"2024-09-26T08:37:01.159631Z","shell.execute_reply.started":"2024-09-26T08:37:01.127540Z","shell.execute_reply":"2024-09-26T08:37:01.158838Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"for i, data in enumerate(train_np):\n  if not 'sentence' in data.keys() or not 'audio' in data.keys():\n    print(i, 'not found')","metadata":{"id":"1hDBvt6S8xnz","execution":{"iopub.status.busy":"2024-09-26T08:37:01.163896Z","iopub.execute_input":"2024-09-26T08:37:01.164356Z","iopub.status.idle":"2024-09-26T08:37:02.779885Z","shell.execute_reply.started":"2024-09-26T08:37:01.164318Z","shell.execute_reply":"2024-09-26T08:37:02.779036Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def prepare_dataset(batch):\n  audio = batch['audio']\n  batch['input_features'] = feature_extractor(audio['array'], sampling_rate=audio['sampling_rate']).input_features[0]\n  batch['labels'] =  tokenizer(batch['sentence']).input_ids\n  return batch\n\n\ntrain_np = train_np.map(\n    prepare_dataset,\n    num_proc=1\n)\n\nval_np = val_np.map(\n    prepare_dataset,\n    num_proc=1\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["7cedebad581d4da8a0550a00d12e22ab","ed083a6195374b6eb9984d9ba272a2e5","a22973f4928b455e8ad60f4e85acc230","b5dea084071945f79596edfff743ec45","a82086c910a749f69e377b763c3b7424","04a05bdb65584670bd74af3b8fce17d6","0de621b1197141dd9daa30fabb88c021","7fd7cbacc6d24a90bff154b6c758ef19","04d19e1d14a24e3a8da979d63003da2a","d4744c0907db4296b0824c2502abe93a","44bd8cc50bc44220ab8dc94c6efe25ff","7d830b8d81ca468bb99309f6027a5892","20cfa50be60f4c8eb0fcdd89e0b9fb5a","cb21a176645d46a8a38418df16eebea5","e921cdaf19654e43ac0c0cffe6e52dda","ce3e4996a7174920bd3df8a8bd4a1a27","906472cc5684426ca4cdb3acc9002d5d","a1fdbdb3fc0348bd9a2c73437c467c5d","346e4f1452e64905a3d980a94db1f4f0","bf08fabde6fb4f07819040e417f6a3ed","f710ff78faef40d7970e6c36376bf86a","b52f94ca818e496ca12fd91139dc067a"]},"id":"hGQnEF3TtW-q","outputId":"c203ab2d-72c0-4c36-cb01-547a049e7f30","execution":{"iopub.status.busy":"2024-09-26T08:37:02.781096Z","iopub.execute_input":"2024-09-26T08:37:02.781441Z","iopub.status.idle":"2024-09-26T08:38:08.884717Z","shell.execute_reply.started":"2024-09-26T08:37:02.781407Z","shell.execute_reply":"2024-09-26T08:38:08.883871Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/381 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1574c5d5c16149e4a3ba15105780a295"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/205 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0984a7e117045299f61d21cf24689f4"}},"metadata":{}}]},{"cell_type":"code","source":"train_np[0].keys(), val_np[0].keys()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5k1WwGOB8Ntu","outputId":"e6fd8ce8-7389-41a1-8284-20aa228a906b","execution":{"iopub.status.busy":"2024-09-26T08:38:08.886009Z","iopub.execute_input":"2024-09-26T08:38:08.886458Z","iopub.status.idle":"2024-09-26T08:38:09.188992Z","shell.execute_reply.started":"2024-09-26T08:38:08.886413Z","shell.execute_reply":"2024-09-26T08:38:09.187978Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(dict_keys(['audio', 'sentence', 'variant', 'input_features', 'labels']),\n dict_keys(['audio', 'sentence', 'variant', 'input_features', 'labels']))"},"metadata":{}}]},{"cell_type":"code","source":"input_str = train_np[0][\"sentence\"]\nlabels = tokenizer(input_str).input_ids\ndecoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\ndecoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n\nprint(f\"Input:                 {input_str}\")\nprint(f\"Decoded w/ special:    {decoded_with_special}\")\nprint(f\"Decoded w/out special: {decoded_str}\")\nprint(f\"Are equal:             {input_str == decoded_str}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-26T08:38:09.190282Z","iopub.execute_input":"2024-09-26T08:38:09.190988Z","iopub.status.idle":"2024-09-26T08:38:10.056732Z","shell.execute_reply.started":"2024-09-26T08:38:09.190939Z","shell.execute_reply":"2024-09-26T08:38:10.055781Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Input:                 म पनि जान्छु है त अहिले लाई ।\nDecoded w/ special:    <|startoftranscript|><|ne|><|transcribe|><|notimestamps|>म पनि जान्छु है त अहिले लाई ।<|endoftext|>\nDecoded w/out special: म पनि जान्छु है त अहिले लाई ।\nAre equal:             True\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Preparing the Model\n","metadata":{}},{"cell_type":"code","source":"model = WhisperForConditionalGeneration.from_pretrained(model_id)\n\nmodel.generation_config.task = 'transcribe'\nmodel.generation_config.language = 'nepali'\nmodel.generation_config.forced_decoder_ids = None","metadata":{"execution":{"iopub.status.busy":"2024-09-26T08:38:10.057887Z","iopub.execute_input":"2024-09-26T08:38:10.058266Z","iopub.status.idle":"2024-09-26T08:38:49.797601Z","shell.execute_reply.started":"2024-09-26T08:38:10.058232Z","shell.execute_reply":"2024-09-26T08:38:49.796700Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42cd1967c2794e4b8a82f8fdf70a2beb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c752ad155a6e40499ac485390233d14e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/3.87k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9361e5f0dc84f90b53b207d6adacc26"}},"metadata":{}}]},{"cell_type":"code","source":"import torch\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Union\n\n@dataclass\nclass DataCollatorSpeechSeq2SeqWithPadding:\n    processor: Any\n    decoder_start_token_id: int\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        # split inputs and labels since they have to be of different lengths and need different padding methods\n        # first treat the audio inputs by simply returning torch tensors\n        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n\n        # get the tokenized label sequences\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n        # pad the labels to max length\n        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n\n        # replace padding with -100 to ignore loss correctly\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n        # if bos token is appended in previous tokenization step,\n        # cut bos token here as it's append later anyways\n        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n            labels = labels[:, 1:]\n\n        batch[\"labels\"] = labels\n\n        return batch\n","metadata":{"id":"8EQbJrq9u-U9","execution":{"iopub.status.busy":"2024-09-26T08:38:49.798761Z","iopub.execute_input":"2024-09-26T08:38:49.799054Z","iopub.status.idle":"2024-09-26T08:38:49.809704Z","shell.execute_reply.started":"2024-09-26T08:38:49.799022Z","shell.execute_reply":"2024-09-26T08:38:49.808721Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n    processor=processor,\n    decoder_start_token_id=model.config.decoder_start_token_id,\n)","metadata":{"id":"OX_ronBaykBB","execution":{"iopub.status.busy":"2024-09-26T08:38:49.810806Z","iopub.execute_input":"2024-09-26T08:38:49.811187Z","iopub.status.idle":"2024-09-26T08:38:53.262214Z","shell.execute_reply.started":"2024-09-26T08:38:49.811123Z","shell.execute_reply":"2024-09-26T08:38:53.261223Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Defining evaluation metrices","metadata":{"id":"EHEutjMXyuMg"}},{"cell_type":"code","source":"metric = evaluate.load('wer')\n\ndef compute_metrics(pred):\n    pred_ids = pred.predictions\n    label_ids = pred.label_ids\n\n    # replace -100 with the pad_token_id\n    label_ids[label_ids == -100] = tokenizer.pad_token_id\n\n    # we do not want to group tokens when computing the metrics\n    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n\n    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n\n    return {'wer': wer}","metadata":{"id":"W3usZ5Vbyrhp","execution":{"iopub.status.busy":"2024-09-26T08:38:53.263397Z","iopub.execute_input":"2024-09-26T08:38:53.263729Z","iopub.status.idle":"2024-09-26T08:38:54.724465Z","shell.execute_reply.started":"2024-09-26T08:38:53.263694Z","shell.execute_reply":"2024-09-26T08:38:54.723752Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0aa56e1b9d2a413997945318824e9274"}},"metadata":{}}]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=out_dir,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    gradient_accumulation_steps=1,\n    learning_rate=0.00001,\n    warmup_steps=500,\n    bf16=False,\n    fp16=True,\n    num_train_epochs=epochs,\n    evaluation_strategy='epoch',\n    logging_strategy='epoch',\n    save_strategy='epoch',\n    predict_with_generate=True,\n    generation_max_length=225,\n    report_to=['tensorboard'],\n    load_best_model_at_end=True,\n    metric_for_best_model='wer',\n    greater_is_better=False,\n    dataloader_num_workers=2,\n    save_total_limit=2,\n    lr_scheduler_type='constant',\n    seed=42,\n    data_seed=42\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K8M8nN7Dy0ff","outputId":"21de1235-42a7-40ed-ce1d-f28af50d9da8","execution":{"iopub.status.busy":"2024-09-26T08:38:54.725552Z","iopub.execute_input":"2024-09-26T08:38:54.725851Z","iopub.status.idle":"2024-09-26T08:38:54.803395Z","shell.execute_reply.started":"2024-09-26T08:38:54.725818Z","shell.execute_reply":"2024-09-26T08:38:54.802434Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    args=training_args,\n    model=model,\n    train_dataset=train_np,\n    eval_dataset=val_np,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    tokenizer=processor.feature_extractor,\n)","metadata":{"id":"xVVbdHAXy31S","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fb8370b7-7138-47e0-8daf-790ff59fd9c0","execution":{"iopub.status.busy":"2024-09-26T08:38:54.804639Z","iopub.execute_input":"2024-09-26T08:38:54.804959Z","iopub.status.idle":"2024-09-26T08:38:55.311497Z","shell.execute_reply.started":"2024-09-26T08:38:54.804899Z","shell.execute_reply":"2024-09-26T08:38:55.310594Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":285},"id":"GEak1sdXy68O","outputId":"c87fec96-aa39-41f1-9234-e44a7b189e5b","execution":{"iopub.status.busy":"2024-09-26T09:00:19.785733Z","iopub.execute_input":"2024-09-26T09:00:19.786649Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='961' max='4800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 961/4800 35:41 < 2:22:50, 0.45 it/s, Epoch 10/50]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Wer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.743000</td>\n      <td>0.559718</td>\n      <td>72.915073</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.307400</td>\n      <td>0.511249</td>\n      <td>68.936496</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.144600</td>\n      <td>0.558583</td>\n      <td>69.013007</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.082800</td>\n      <td>0.555373</td>\n      <td>65.876052</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.047500</td>\n      <td>0.591383</td>\n      <td>67.482785</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.032700</td>\n      <td>0.660863</td>\n      <td>66.564652</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.021000</td>\n      <td>0.671670</td>\n      <td>65.263963</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.021700</td>\n      <td>0.719820</td>\n      <td>66.029074</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.013000</td>\n      <td>0.761301</td>\n      <td>67.482785</td>\n    </tr>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='50' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/52 01:20 < 00:03, 0.61 it/s]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\nYou have passed task=transcribe, but also have set `forced_decoder_ids` to [[1, 50259], [2, 50359], [3, 50363]] which creates a conflict. `forced_decoder_ids` will be ignored in favor of task=transcribe.\nThe attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2612: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = load_dataset(\"spktsagar/openslr-nepali-asr-cleaned\", name=\"cleaned\", split='train')","metadata":{"id":"gogJaZmwMsTv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GM-TM6JcNMF_","outputId":"a1fee087-ed2b-4d29-d00b-6c0a17ea1897"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### For inference","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader\ndataloader = DataLoader(val_np, batch_size=4, collate_fn=data_collator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Iterate through batches and get model predictions\nfor batch in dataloader:\n    input_features = batch[\"input_features\"]\n    labels = batch[\"labels\"]\n\n    # Perform inference (using no_grad for evaluation)\n    with torch.no_grad():\n        generated_ids = model.generate(input_features, language='ne')\n\n    # Decode the predicted token IDs into text\n    predictions = processor.batch_decode(generated_ids, skip_special_tokens=True)\n    sents = processor.batch_decode(labels, skip_special_tokens=True)\n    # Print or store predictions\n    for pred, sen in zip(predictions, sents):\n        print(f'GT:{sen}.......... Pred: {pred}')\n        \n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}